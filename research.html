<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Research Experience | Naveena Pokala</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #0f172a;
      color: #e5e7eb;
      padding: 60px;
    }
    h1 {
      font-size: 36px;
    }
    h2 {
      color: #38bdf8;
      margin-top: 40px;
    }
    ul {
      max-width: 900px;
      line-height: 1.6;
    }
    li {
      margin-bottom: 10px;
    }
    a {
      color: #38bdf8;
      text-decoration: none;
    }
  </style>
</head>
<body>

  <h1>Research Experience</h1>

  <h2>
    University of North Carolina at Greensboro — AI/ML Research Assistant
  </h2>
  <p><em>February 2025 – Present</em></p>

  <ul>
    <li>
      Built end-to-end training and evaluation pipelines for LLM-based models,
      integrating LLaMA-2 embeddings with CNN architectures to process 10,000+
      natural language documents.
    </li>
    <li>
      Engineered a time-series ML modeling framework combining textual signals
      from annual reports with numerical market data for predictive analytics.
    </li>
    <li>
      Developed scalable Python ML pipelines for data ingestion, preprocessing,
      embedding generation, model training, and evaluation.
    </li>
    <li>
      Designed retrieval systems using vector embeddings and contextual chunking
      to align long-form NLP text with temporal events.
    </li>
    <li>
      Built distributed PyTorch training pipelines optimized for GPU utilization
      and large-scale batch processing.
    </li>
    <li>
      Improved model performance by 32–45% (lower MAPE) compared to ARIMA
      baselines using hybrid LLM + time-series modeling.
    </li>
    <li>
      Designed and validated novel financial features using statistical modeling
      and hypothesis testing on noisy, real-world datasets.
    </li>
  </ul>

  <p>
    <a href="index.html">← Back to Home</a>
  </p>

</body>
</html>
