<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Projects | Naveena Pokala</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- Google Font -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
      background: radial-gradient(circle at top, #0f172a, #020617);
      color: #e5e7eb;
      margin: 0;
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 24px;
    }

    .container {
      width: 100%;
      max-width: 1000px;
    }

    h2 {
      font-size: 34px;
      margin: 0 0 24px;
      color: #f8fafc;
    }

    h3 {
      font-size: 22px;
      margin: 0 0 6px;
      color: #f8fafc;
    }

    p {
      font-size: 15px;
      color: #cbd5f5;
      margin: 0 0 14px;
    }

    ul {
      padding-left: 20px;
      margin: 0;
      line-height: 1.7;
      color: #cbd5f5;
      font-size: 15px;
    }

    li {
      margin-bottom: 10px;
    }

    .card {
      background: rgba(30, 41, 59, 0.65);
      border: 1px solid rgba(148, 163, 184, 0.18);
      border-radius: 18px;
      padding: 36px;
      margin-bottom: 28px;
      box-shadow: 0 30px 60px rgba(0,0,0,0.45);
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }

    .card:hover {
      transform: translateY(-4px);
      box-shadow: 0 40px 80px rgba(0,0,0,0.55);
    }

    .back-btn {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      margin-bottom: 24px;
      font-size: 14px;
      font-weight: 500;
      color: #38bdf8;
      background: rgba(56, 189, 248, 0.1);
      border: 1px solid rgba(56, 189, 248, 0.3);
      padding: 8px 14px;
      border-radius: 8px;
      cursor: pointer;
      text-decoration: none;
    }

    .back-btn:hover {
      background: rgba(56, 189, 248, 0.2);
      border-color: #38bdf8;
    }
  </style>
</head>

<body>

  <div class="container">

    <!-- Back Button -->
    <a href="javascript:history.back()" class="back-btn">‚Üê Back</a>

    <h2>Machine Learning Experience</h2>

    <!-- FLAGSHIP PROJECT -->
    <div class="card">
      <h3>AI/ML Research Assistant ‚Äî Stock Price Prediction (UNC Greensboro)</h3>
      <p><em>February 2025 ‚Äì Present</em></p>

      <ul>
        <li>
          Built end-to-end pipelines for LLM-based models, integrating LLaMA-2
          embeddings with CNN architectures to process 10,000+ annual report documents.
        </li>
        <li>
          Engineered scalable Python ML pipelines for data ingestion, preprocessing,
          embedding generation, model training, and evaluation.
        </li>
        <li>
          Developed retrieval systems using vector embeddings and contextual chunking
          to align long-form NLP text with temporal market events.
        </li>
        <li>
          Built distributed PyTorch training pipelines optimized for GPU utilization
          and large-scale batch processing.
        </li>
        <li>
          Achieved 32‚Äì45% lower MAPE compared to ARIMA baselines using hybrid
          LLM + time-series modeling.
        </li>
        <li>
          üìÑ <strong>Paper accepted:</strong>
          <em>Stock Price Prediction Based on Annual Reports Using Large Language Models</em>
        </li>
      </ul>
    </div>

    <!-- SECONDARY PROJECTS -->
    <h2>Projects</h2>

    <div class="card">
      <h3>AI-Powered Academic Assistant</h3>
      <p><em>February 2025</em></p>

      <ul>
        <li>
          Developed a multi-agent LLM workflow using LangChain to retrieve,
          summarize, and validate complex academic content.
        </li>
        <li>
          Implemented a retrieval-augmented generation (RAG) pipeline using FAISS,
          HuggingFace embeddings, and Zephyr-7B.
        </li>
        <li>
          Built and deployed a FastAPI backend supporting parallel inference,
          caching, and latency-optimized retrieval.
        </li>
        <li>
          Improved model prediction accuracy by 35% through advanced prompt
          engineering and system-level optimization.
        </li>
        <li>
          Achieved sub-200ms inference latency through performance profiling.
        </li>
      </ul>
    </div>

  </div>

</body>
</html>
