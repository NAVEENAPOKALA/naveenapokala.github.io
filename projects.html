<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Projects | Naveena Pokala</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- Google Font -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

  <style>
    body {
      font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont, sans-serif;
      background: radial-gradient(circle at top, #0f172a, #020617);
      color: #e5e7eb;
      margin: 0;
      padding: 80px 10%;
    }

    h1 {
      font-size: 48px;
      margin-bottom: 10px;
    }

    h2 {
      font-size: 28px;
      margin-top: 80px;
      color: #e5e7eb;
    }

    h3 {
      margin-top: 0;
      font-size: 22px;
    }

    p {
      max-width: 820px;
      line-height: 1.7;
      font-size: 17px;
      color: #cbd5f5;
    }

    ul {
      margin-top: 12px;
      max-width: 900px;
      line-height: 1.7;
    }

    li {
      margin-bottom: 10px;
    }

    a {
      color: #38bdf8;
      text-decoration: none;
      font-weight: 500;
    }

    a:hover {
      text-decoration: underline;
    }

    .card {
      background: rgba(30, 41, 59, 0.65);
      border: 1px solid rgba(148, 163, 184, 0.15);
      border-radius: 16px;
      padding: 32px;
      margin-top: 40px;
      max-width: 1050px;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }

    .card:hover {
      transform: translateY(-4px);
      box-shadow: 0 20px 40px rgba(0,0,0,0.35);
    }

    .badge {
      display: inline-block;
      background: rgba(56, 189, 248, 0.18);
      color: #38bdf8;
      padding: 6px 14px;
      border-radius: 999px;
      font-size: 13px;
      font-weight: 600;
      margin-bottom: 14px;
    }

    .back {
      margin-top: 90px;
    }
  </style>
</head>

<body>

  <h1>Machine Learning Experience/Projects</h1>
  <!-- <p>
    Selected applied machine learning, GenAI, and research projects demonstrating
    end-to-end modeling, evaluation, and production deployment.
  </p> -->

  <!-- FLAGSHIP -->
  <!-- <h2>Flagship Research Project</h2> -->

  <div class="card">
    <!-- <span class="badge">Flagship Â· Paper Accepted</span> -->
    <h3>AI/ML Research Assistant â€” Stock Price Prediction (UNC Greensboro)</h3>
    <p><em>February 2025 â€“ Present</em></p>

    <ul>
      <li>
        Built end-to-end training and evaluation pipelines for LLM-based models,
        integrating LLaMA-2 embeddings with CNN architectures to process 10,000+
        annual report documents.
      </li>
      <li>
        Designed a hybrid modeling framework combining textual signals from
        financial reports with numerical time-series market data.
      </li>
      <li>
        Engineered scalable Python ML pipelines for data ingestion, preprocessing,
        embedding generation, model training, and evaluation.
      </li>
      <li>
        Developed retrieval systems using vector embeddings and contextual chunking
        to align long-form NLP text with temporal market events.
      </li>
      <li>
        Built distributed PyTorch training pipelines optimized for GPU utilization
        and large-scale batch processing.
      </li>
      <li>
        Achieved 32â€“45% lower MAPE compared to ARIMA baselines using hybrid
        LLM + time-series modeling.
      </li>
      <li>
        ðŸ“„ <strong>Paper accepted:</strong> <em>Stock Price Prediction Based on Annual Reports Using Large Language Models</em>.
      </li>
    </ul>
  </div>

  <!-- SECONDARY -->
  <!-- <h2>Applied GenAI Project</h2> -->

  <div class="card">
    <!-- <span class="badge">GenAI System</span> -->
    <h3>AI-Powered Academic Assistant</h3>
    <p><em>February 2025</em></p>

    <ul>
      <li>
        Developed a multi-agent LLM workflow using LangChain to retrieve,
        summarize, and validate complex academic content.
      </li>
      <li>
        Implemented a retrieval-augmented generation (RAG) pipeline using FAISS,
        HuggingFace embeddings, and Zephyr-7B.
      </li>
      <li>
        Built and deployed a FastAPI backend supporting parallel inference,
        caching, and latency-optimized retrieval.
      </li>
      <li>
        Improved model prediction accuracy by 35% through prompt engineering
        and system-level optimization.
      </li>
      <li>
        Achieved sub-200ms inference latency through performance profiling.
      </li>
    </ul>
  </div>
